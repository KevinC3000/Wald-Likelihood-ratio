{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16f83bd",
   "metadata": {},
   "source": [
    "# Lecture: Wald Test and Likelihood-ratio Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54984a",
   "metadata": {},
   "source": [
    "The Wald test, the Likelihood-ratio test, together with the Lagrange multiplier test are considered as the three classical approaches to hypothesis testing.\n",
    "\n",
    "In previous lectures we've considered tests for various statistics and hypotheses, but what about regression coefficients? Today, we'll cover the first two hypothesis tests that we can use to test the significance of a single coefficient, say $\\theta$, or the joint significance of of several components of $\\beta$. We begin from introducing the Wald test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7dd09",
   "metadata": {},
   "source": [
    "## Wald Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c85b7",
   "metadata": {},
   "source": [
    "This portion of the lecture details the different forms of the Wald Test and there many uses. The general use of the Wald Test is to analyze and determine the probability of a parameter(s) in a model taking a specific value. However as we will see, the most common and primary use is the determine whether a coefficient is signifigant or not. We will begin with the Wald Test of a single parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80661e",
   "metadata": {},
   "source": [
    "### Single Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3cdf3b",
   "metadata": {},
   "source": [
    "The null and alternative hypothesis for a testing a single parameter $\\theta$ follow the general form of:\n",
    "\n",
    "$$\n",
    "    H_0: \\theta = \\theta_0\\\\\n",
    "    H_a: \\theta \\neq \\theta_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c9a9a",
   "metadata": {},
   "source": [
    "The Wald Test statistic is then written as:\n",
    "\n",
    "$$\n",
    "    W = \\frac{(\\hat{\\theta} - \\theta_0)^2}{Var(\\hat{\\theta})},\n",
    "$$\n",
    "\n",
    "where $\\hat{\\theta}$ is the M.L.E. of the actual parameter $\\theta$, which follows an asymptotic $\\chi^2$-distribution with one degree of freedom. However an alternative form the statistic can be obtained be taking the square root of $W$.\n",
    "\n",
    "$$\n",
    "    \\sqrt{W} = \\frac{\\hat{\\theta} - \\theta_0}{se(\\hat{\\theta})}\n",
    "$$\n",
    "\n",
    "Here $se(\\hat{\\theta})$ represents the standard error of $\\hat{\\theta}$, which is obtained by taking the square root of its variance, however this value is not always known. Under the assumption of normality of the data, this ratio will follow a Student's t distribution, which makes calculating a p-value relatively simple. Even better, if the standard error is known the ratio has approximately a standard normal distribution. This means that one can treat it as a z-statistic and perform a z-test when deciding whether to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9587ae0",
   "metadata": {},
   "source": [
    "The Wald Test is most commonly used to determine whether a parameter has any significance in a model. In this case “significant” means that they add something to the model; parameters that add nothing can be removed without affecting the model in any meaningful way. This is done using the null hypothesis $H_0: \\theta = 0$, which simplifies our test statistic to:\n",
    "\n",
    "$$\n",
    "    \\sqrt{W} = \\frac{\\hat{\\theta}}{se(\\hat{\\theta})}\n",
    "$$\n",
    "\n",
    "The intuition about how the test works is that it tests how far the estimated parameters are from zero (or any other value under the null hypothesis) in standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af96ff0",
   "metadata": {},
   "source": [
    "\\begin{example}\\label{example:1}\n",
    "Say we have performed a linear regression on a large approximately normally distributed data set $(n > 30)$, and obtained a model $y = 4.2 + .38x_1 + .86x_2$ with known $se(\\beta_2) = .409$. We want to determine whether variable $x_2$ is has any signifigance in our model. We follow by performing a Wald Test on $\\beta_2$ with null hypothesis $H_0: \\beta_2 = 0$.\n",
    "\n",
    "We first find our test statistic, which in this case will be a z-statistic since we are working with a large sample.\n",
    "\n",
    "$$\n",
    "    Z = \\frac{\\hat{\\beta_2}}{se(\\hat{\\beta_2})} = \\frac{.86}{.409} = 2.10\n",
    "$$\n",
    "\n",
    "We can then calculate the p-value using a z-test:\n",
    "\n",
    "$$\n",
    "    p = 2 * \\mathbb{P}(Z > 2.10) = .036\n",
    "$$\n",
    "\n",
    "With a critical value of $\\alpha = .05$ we would reject the null hypothesis and say that $\\beta_2$ is significantly different from zero with 95% confidence.\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30ce71",
   "metadata": {},
   "source": [
    "\\begin{example}\n",
    "The Wald Test can also be used to construct a confidence interval for a parameter. Looking at our example, we can again use a z-test to create a 95% $(\\alpha = .05)$ confidence interval for $\\beta_2$ as follows:\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta_2} \\pm z_{1-\\alpha/2}*se(\\hat{\\beta_2}) = .86 \\pm 0.80164 = [.058, 1.66]\n",
    "$$\n",
    "\n",
    "* Note: If the standard error of $\\beta_2$ was unknown, then the process would be almost the same but with an estimate of the standard error obtained from the residual sum of squares and a t-test being used as a substitute in all instances where we have used a z-test.\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1478957",
   "metadata": {},
   "source": [
    "### Mulitple Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef127af",
   "metadata": {},
   "source": [
    "The Wald test can also be used to test the joint significance of several coefficients. For instance, take a vector of parameters $\\beta'$ and seperate into two components $\\beta_1'$ and $\\beta_2'$ with $p_1$ and $p_2$ elements respectively. Now consider the hypothesis:\n",
    "\n",
    "$$\n",
    "    H_0: \\beta_1 = 0\n",
    "$$\n",
    "\n",
    "Given this setup, the equation for the Wald Test statistic would then be:\n",
    "\n",
    "$$\n",
    "    W = \\hat{\\beta_1'} Var^{-1}(\\hat{\\beta_1}) \\hat{\\beta_1}\n",
    "$$\n",
    "\n",
    "* Note: If $\\beta_1'$ contains a single coefficient and $p_1 = 1$, this formula will reduce to the one for a single parameter as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054bb7f",
   "metadata": {},
   "source": [
    "This quadratic form of $W$ will take the form of a $\\chi^2$ distribution with $p_1$ degrees of freedom in large samples regardless of whether the standard error is known or estimated. This also holds in smaller samples under the assumption of normality and with a known standard error.\n",
    "\n",
    "However, in small samples where the standard error is estimated using the residual sum of squares with $n - p$ d.f., the distribution of $W/p_1$ will be an $F$ with $p_1$ and $n-p$ degrees of freedom.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98f152",
   "metadata": {},
   "source": [
    "## Likelihood-ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e278d3",
   "metadata": {},
   "source": [
    "The Likelihood-ratio test compares two competing statistcal models based on their log-likelihoods. we discuss the Likelihood-ratio test in two cases, i.e. likelihood-ratio test with simple hypotheses and the general likelihood-ratio test. In general case, one model will be imposed some constraint while the other one will use the entire parameter space. And what the likelihood-ratio test will tell us is that whether there is any difference on fitting data when using these two models. If there is not a significant improvement when using the unconstrained one, we can simply choose to use the constrained one which uses less data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca88106",
   "metadata": {},
   "source": [
    "In this part,we start with the Neyman–Pearson lemma, which pave the way for the test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c952980",
   "metadata": {},
   "source": [
    "### The Neyman–Pearson Lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ef3e0",
   "metadata": {},
   "source": [
    "Let $H_0$ and $H_1$ be simple hypotheses. The simple hypotheses means two sets of data come from the smae distributions, either both discrete or both continuous. For a constant $c > 0$, suppose that the likelihood ratio test which rejects $H_0$ when $L(x) < c$ has a significance level $\\alpha$. Then for any other test of $H_0$ with significance level at most $\\alpha$, its power against $H_1$ is at most the power of this likelihood ratio test.\n",
    "\n",
    "What the Neyman-Pearson Lemma demonstrates is that when we are comparing two models without unknown parameters, the likelihood-ratio test has the highest power among all other tests at a specified significance level $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dda20",
   "metadata": {},
   "source": [
    "### Likelihood Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90fac3",
   "metadata": {},
   "source": [
    "Let $X_1, X_2, \\dots, X_n$ be a random sample from a distribution with a parameter $\\theta$. We observe that $X_1 = x_1, X_2 = x_2, \\dots, X_n = x_n$.\n",
    "\n",
    "* If the $X_i$'s are discrete, then the likelihood function is defined as the product of each $X_i$'s probability mass function depending on the parameter $\\theta$.\n",
    "\n",
    "$$L(x_1,x_2,\\dots,x_n;\\theta) = P_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta)$$\n",
    "\n",
    "* If the $X_i$'s are jointly continuous, then the likelihood function is defined as the product of density function $f$ of each $x$ depending on the parameter $\\theta$.\n",
    "\n",
    "$$L(x_1,x_2,\\dots,x_n;\\theta) = f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta)$$\n",
    "\n",
    "And the likelihood function tends to be highest near the true value of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff4a8e",
   "metadata": {},
   "source": [
    "## Likelihood-ratio Test with Simple Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7efea",
   "metadata": {},
   "source": [
    "The distribution of the data of two models are fully specified under both the null hypothesis and the alternative hypothesis.\n",
    "\n",
    "$$\n",
    "    H_0: \\theta = \\theta_0\\\\\n",
    "    H_1: \\theta = \\theta_1\n",
    "$$\n",
    "\n",
    "We define\n",
    "\n",
    "$$LR = \\lambda(x_1,x_2,\\dots,x_n) = \\frac{L(x_1,x_2,\\dots,x_n;\\theta_0)}{L(x_1,x_2,\\dots,x_n;\\theta_1)}$$\n",
    "\n",
    "Just like the likelihood value, we know the log-likelihood value of regression model is also a way to measure the goodness of fit for a model. The higher the log-likelihood, the better the model fits the dataset.\n",
    "\n",
    "In this sense, by our definition, we know the likelihood ratio $\\lambda$ is small if the alternative model fits better the data than the null model. And vice versa, $\\lambda$ is large if the null model fits better the data than the alternative model.\n",
    "\n",
    "To perform a likelihood ratio test, we choose a constant $c$. We reject $H_0$ if $\\lambda < c$ and accept it if $\\lambda \\geq c$. The value of $c$ can be chosen based on the desired $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984bf9a",
   "metadata": {},
   "source": [
    "\\begin{example}\n",
    "\n",
    "Consider a motion sensor for museums that uses infrared waves to detect thieves. The system receives a sinal and, based on the received signal, it needs to decide whether or not there is someone who approaches the collection without getting permission. Let X be the received signal. Suppose that we know:\n",
    "\n",
    "$X = W$, if not detect people in the range.\n",
    "\n",
    "$X = 1 + W$, if detect people in the range.\n",
    "\n",
    "where $W \\sim \\mathcal{N}(0,\\sigma^2 = \\frac{1}{4})$. Thus, we can write $X = \\theta + W$, where $\\theta = 0$ if there is no people being detected in the range, and $\\theta = 1$ if there is at least one person being detected in the range. $H_0$ and $H_1$ are defined as follows:\n",
    "\n",
    "$H_0: \\theta = \\theta_0 = 0$,\n",
    "\n",
    "$H_1: \\theta = \\theta_1 = 1$.\n",
    "\n",
    "Let $X = x$. Design a level 0.05 test ($\\alpha = 0.05$) to decide between $H_0$ and $H_1$.\n",
    "\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200353d",
   "metadata": {},
   "source": [
    "Under $H_0$, $X \\sim \\mathcal{N}(0,\\sigma^2 = \\frac{1}{4})$. Therefore, $L(x;\\theta_0) = f_X(x;\\theta_0) = \\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{4x^2}{2}} = \\sqrt{\\frac{2}{\\pi}}e^{-2x^2}$\n",
    "\n",
    "On the other hand, under $H_1$, $X \\sim \\mathcal{N}(1,\\sigma^2 = \\frac{1}{4})$. Therefore, $L(x;\\theta_1) = f_X(x;\\theta_1) = \\frac{2}{\\sqrt{2\\pi}}e^{-\\frac{4(x-1)^2}{2}} = \\sqrt{\\frac{2}{\\pi}}e^{-2(x-1)^2}$\n",
    "\n",
    "Therefore, $\\lambda(x) = \\frac{L(x;\\theta_0)}{L(x;\\theta_1)} = e^{-2x^2+2(x-1)^2} = e^{2-4x}$.\n",
    "\n",
    "Thus, we accept $H_0$ if $e^{2-4x}\\geq c$,\n",
    "\n",
    "where $c$ is the threshold. Equivalently, we accept $H_0$ if $x \\leq \\frac{1}{4}(2 - \\ln c)$.\n",
    "\n",
    "Let us define $c^{'} = \\frac{1}{4}(2 - \\ln c)$, where $c^{'}$ is a new threshold. Remember that $x$ is the observed value of the random variable $X$. Thus, we can summarize the decision rule as follows. We accept $H_0$ if $X \\leq c^{'}$.\n",
    "\n",
    "Because the problem is designed for a motion sensor which protects the collection from being stolen, we would accept error that it detects a theft even when there is no person in the range. It means we would prefer the type 1 error that rejecting the null hypothesis when it's actually true rather than type 2 error.\n",
    "\n",
    "Let $\\alpha = \\mathbb{P}(type \\, I \\, error) = \\mathbb{P}(Reject \\, H_0 | H_0) = \\mathbb{P}(X > c^{'}|H_0) = \\mathbb{P}(X > c^{'}) = 1 - \\Phi(2c^{'})$.\n",
    "\n",
    "Calculating $\\alpha = 0.05 = 1 - \\Phi(2c^{'})$, we get $c^{'} = \\frac{1}{2}\\Phi^{-1}(1-\\alpha) = \\frac{1}{2}\\Phi^{-1}(0.95) = 0.8225$\n",
    "\n",
    "Therefore, We accept $H_0$ if $X \\leq 0.8225$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8d68f",
   "metadata": {},
   "source": [
    "\\begin{example}\n",
    "\n",
    "Suppose $X_1, \\dots, X_n$ is a random sample of size n from an exponential distribution $f(x|\\theta) = \\frac{1}{\\theta}e^{-\\frac{x}{\\theta}}$, $x>0$\n",
    "\n",
    "Conduct the following simple hypothesis testing problem:\n",
    "\n",
    "$H_0: \\theta = \\theta_0 = 2$,\n",
    "\n",
    "$H_1: \\theta = \\theta_1 = 1$,\n",
    "\n",
    "Let $X = x$. Design a level 0.05 test ($\\alpha = 0.05$) of size $n = 5$ from an exponential distribution to decide between $H_0$ and $H_1$.\n",
    "\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feece942",
   "metadata": {},
   "source": [
    "Under $H_0$, the likelihood functioin $L(x_1,x_2,\\dots,x_n;\\theta_0) = f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta_0) = \\prod_{i=1}^{n}\\frac{1}{\\theta_0}e^{-\\frac{x_i}{\\theta_0}} = \\theta_0^{-n}e^{-\\sum\\frac{x_i}{\\theta_0}}$\n",
    "\n",
    "Similarly, Under $H_1$, the likelihood functioin $L(x_1,x_2,\\dots,x_n;\\theta_1) = f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta_1) = \\theta_1^{-n}e^{-\\sum\\frac{x_i}{\\theta_1}}$\n",
    "\n",
    "We define the likelihood ratio as follows:\n",
    "\n",
    "$ LR = \\lambda(x) = \\frac{f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta_0)}{f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta_1)} = \\frac{\\theta_0^{-n}e^{-\\sum\\frac{x_i}{\\theta_0}}}{\\theta_0^{-n}e^{-\\sum\\frac{x_i}{\\theta_1}}} = (\\frac{\\theta_0}{\\theta_1})^{-n}e^{(\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0})\\sum x_i}$\n",
    "\n",
    "If the data supports $H_1$, then the likelihood function $f_{X_1X_2 \\dots X_n}(x_1,x_2,\\dots,x_n;\\theta_1)$ should be large, therefore the $LR = \\lambda$ is small. Thus, we reject the null hypothesis if $LR \\leq c$, where $c$ is a constant such that $\\mathbb{P}(LR \\leq c) = \\alpha$ under the null hypothesis $H_0$.\n",
    "\n",
    "Setting $\\alpha = \\mathbb{P}(LR \\leq c) = \\mathbb{P}((\\frac{\\theta_0}{\\theta_1})^{-n}e^{(\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0})\\sum x_i} \\leq c) = \\mathbb{P}(e^{(\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0})\\sum x_i} \\leq (\\frac{\\theta_0}{\\theta_1})^{n}c) = \\mathbb{P}((\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0})\\sum x_i \\leq \\ln [(\\frac{\\theta_0}{\\theta_1})^{n}c)]) = \\mathbb{P}(\\sum x_i \\leq \\frac{\\ln c + n\\ln \\theta_0 - n\\ln \\theta_1}{\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0}})$\n",
    "\n",
    "Let $\\frac{2}{\\theta_0}\\sum x_i = V$, we get $\\alpha = \\mathbb{P}(V \\leq \\frac{2}{\\theta_0}\\frac{\\ln c + n\\ln \\theta_0 - n\\ln \\theta_1}{\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0}})$\n",
    "\n",
    "Because a chi-squared distribution with 2 degrees of freedom (k = 2) is an exponential distribution with a mean value of 2 (rate $\\theta = 2$ ), we know under $H_0$, $\\frac{2}{\\theta_0}X_i$ follows $\\chi_2^2$ distribution, consequently, $V$ follows a Chi square distribution with $2n$ degrees of freedom.\n",
    "\n",
    "So in this question, we plug in $n = 5$ and look at chi-square table under $2n = 10$ degrees of freedom under which there is $\\alpha = 0.05$ area. We obtain a result 3.94. So $\\mathbb{P}(\\frac{2}{2}\\sum x_i \\leq 3.94) = 0.05$. This implies that we should reject $H_0$ if $\\sum x_i \\leq 3.94$.\n",
    "\n",
    "By solving $\\frac{2}{\\theta_0}\\frac{\\ln c + n\\ln \\theta_0 - n\\ln \\theta_1}{\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0}} = 3.94$ with $\\theta_0 = 2$, $\\theta_1 = 1$, and $n = 5$, we get $c = 0.8034$\n",
    "\n",
    "Therefore, we reject the null hypothesis $H_0$ if $(\\frac{\\theta_0}{\\theta_1})^{-n}e^{(\\frac{1}{\\theta_1}-\\frac{1}{\\theta_0})\\sum x_i} = (\\frac{2}{1})^{-5}e^{(\\frac{1}{1}-\\frac{1}{2})\\sum x_i} = \\frac{1}{32}e^{\\frac{1}{2}\\sum x_i} \\leq 0.8034 = c$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae0a35",
   "metadata": {},
   "source": [
    "## General Likelihood-ratio Test (GLRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1a5d",
   "metadata": {},
   "source": [
    "General likelihood-ratio test is used to test two compositional sets of data, for example we say $S_0$ and $S_1$ where $S_1$ = $S_0^c$, i.e. $S_0 \\cup S_1 = S$ where $S$ denotes the full data set. \n",
    "\n",
    "Consider the following hypotheses:\n",
    "\n",
    "$$\n",
    "    H_0:\\theta \\in S_0\\\\\n",
    "    H_1:\\theta \\in S_1\n",
    "$$.\n",
    "\n",
    "But unlike the likelihood-ratio test with simple hypotheses, when choosing the test statistics $LR$, instead of using the division between $L(x_1,x_2,\\dots,x_n;\\theta_0)$ and $L(x_1,x_2,\\dots,x_n;\\theta_1)$, GLRT will use the supremum of the likelihood when picking from the full set $S$ as the unconstrained part we introduced before to calculate $LR = \\lambda$.\n",
    "\n",
    "The difinition of supremum is given by:\n",
    "\n",
    "The supremum (abbreviated sup) of a subset $S$ of a partially ordered set $P$ is the least element in $P$ that is greater than or equal to all elements of $S$, if such an element exists. The supremum is also referred to as the least upper bound.\n",
    "\n",
    "So, the difinition of GLRT is given by:\n",
    "\n",
    "Let $X_1, X_2, X_3, \\dots, X_n$ be a random sample from a distribution with a parameter $\\theta$. Suppose that we have observed $X_1 = x_1, X_2 = x_2,\\dots, X_n = x_n$.\n",
    "\n",
    "Define:\n",
    "\n",
    "$$LR = \\lambda(x_1,x_2,\\dots,x_n) = \\frac{l_0}{l} = \\frac{sup \\{ L(x_1,x_2,\\dots,x_n;\\theta):\\theta \\in S_0 \\}}{sup \\{ L(x_1,x_2,\\dots,x_n;\\theta):\\theta \\in S \\}}$$\n",
    "\n",
    "The idea behind the GLRT is that: We first find the likelihood corresponding to the most likely values of $\\theta$ in $\\S_0$ and $S_1$ respectively. Denote $l_1 = sup \\{ L(x_1,x_2,\\dots,x_n;\\theta):\\theta \\in S_0 \\}$. In two extreme cases. If $l_0 = l$, then we can say that the most likely value of $\\theta$ blongs to $S_0$. In this sense, we should not reject $H_0$. On the other hand, if $\\frac{l_0}{l_1}$ is much smaller than 1, we shoud reject $H_0$ in fovor of $H_1$. \n",
    "\n",
    "To conduct a likelihood-ratio test, we choose a threshold $0 \\leq c \\leq 1$ and compare $\\frac{l_0}{l}$ to $c$.\n",
    "\n",
    "Notice that $l$ denotes the supreme likelihood which comes from the entire parameter space, the unconstrained one as we mentioned before. While $l_0$ denotes the constrained one from partial parameter space. So, $0 \\leq \\frac{l_0}{l} \\leq 1$ because constrained one can never surpass the unconstrained one.\n",
    "\n",
    "If $\\frac{l_0}{l} \\geq c$, we accept $H_0$. If $\\frac{l_0}{l} \\leq c$, we reject $H_0$. The value of $c$ can be chosen based on the desired significance level $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822dbfe",
   "metadata": {},
   "source": [
    "### Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f5eac9",
   "metadata": {},
   "source": [
    "With the same idea, the test statistics of the likelyhood-ratio test is often defined as the difference between the log-likelihoods:\n",
    "\n",
    "$$\\lambda_{LR} = -2 \\ln [\\frac{sup_{\\theta \\in \\theta_0}L(\\theta)}{sup_{\\theta \\in \\theta}L(\\theta)}] = -2[l(\\theta_0)-l(\\hat{\\theta})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e0b2b",
   "metadata": {},
   "source": [
    "### Wilks' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fd500",
   "metadata": {},
   "source": [
    "Assuming $H_0$ is true, as the sample size $n$ approaches $\\infty$, the test statistic $\\lambda_{LR}$ will asympotically chi-squared distributed ($\\chi^2$) with degrees of freedom equal to the difference in dimensionality of $\\theta$ and $\\theta_0$.\n",
    "\n",
    "Wilks' theorem implies that for a great variety of hypotheses, we can calculate the likelihood ratio $\\lambda$ for the data and then compare the observed $\\lambda_{LR}$ to the $\\chi^2$ value corresponding to the desired significance level $\\alpha$.\n",
    "\n",
    "$$\\lambda_{LR} = -2[l(\\theta_0)-l(\\hat{\\theta})] \\stackrel{H_0}{\\sim}\\chi_q^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bc24b",
   "metadata": {},
   "source": [
    "## LRT in Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62a5f5",
   "metadata": {},
   "source": [
    "In linear regression, a likelihood ratio test compares how well two nested regression models fit the data and determines which one fits better.\n",
    "\n",
    "A nested model is a regression model that contains a subset of the predictor variables in another regression model. We can consider nested model as $l_0$ and the full model as $l$.\n",
    "\n",
    "Suppose we have a regression model with four predictor variables: \n",
    "\n",
    "$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\epsilon$ \n",
    "\n",
    "A nested model of the regression model above which only include partial original predictor variables:\n",
    "\n",
    "$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon$\n",
    "\n",
    "Our goal is to determine whether these two models are significantly different. We can perform a likelihood-ratio test which uses the following hypotheses:\n",
    "\n",
    "$H_0$: The full model and the nested model fit the data equally well. Thus, we choose to use the nested model as it contains less parameter and easier to compute.\n",
    "\n",
    "$H_1$: The full model fits the data significantly better than the nested model. Thus, we should use the full model because the nested model cannot represent the true condition.\n",
    "\n",
    "Comparing to the given p-value, if we can reject $H_0$, then we can conclude that the full model offers a significantly better fit than the nested model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311a95b",
   "metadata": {},
   "source": [
    "\\begin{example}\n",
    "\n",
    "With the given dataset, we are wondering whether we can use the nested regression model to substitute the full regression model. \n",
    "\n",
    "significance level $\\alpha$ is given by 0.05\n",
    "\n",
    "Two models are given below:\n",
    "\n",
    "Full model: $mpg = \\beta_0 + \\beta_1disp + \\beta_2carb + \\beta_3hp + \\beta_4cyl$\n",
    "\n",
    "Reduced model: $mpg = \\beta_0 + \\beta_1disp + \\beta_2carb$\n",
    "\n",
    "$H_0$: There is no significant difference. Can use nested regression model to substitute the full regression model.\n",
    "\n",
    "$H_1$: There is a significant difference. Cannot use nested regression model to substitute the full regression model.\n",
    "\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb94a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bc5170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiant</td>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duster 360</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merc 240D</td>\n",
       "      <td>24.4</td>\n",
       "      <td>4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merc 230</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Merc 280</td>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merc 280C</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merc 450SE</td>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Merc 450SL</td>\n",
       "      <td>17.3</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merc 450SLC</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cadillac Fleetwood</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lincoln Continental</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chrysler Imperial</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fiat 128</td>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Honda Civic</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toyota Corolla</td>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota Corona</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dodge Challenger</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AMC Javelin</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Camaro Z28</td>\n",
       "      <td>13.3</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pontiac Firebird</td>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fiat X1-9</td>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Porsche 914-2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lotus Europa</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ford Pantera L</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ferrari Dino</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Maserati Bora</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Volvo 142E</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  \\\n",
       "0             Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1   \n",
       "1         Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1   \n",
       "2            Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1   \n",
       "3        Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0   \n",
       "4     Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0   \n",
       "5               Valiant  18.1    6  225.0  105  2.76  3.460  20.22   1   0   \n",
       "6            Duster 360  14.3    8  360.0  245  3.21  3.570  15.84   0   0   \n",
       "7             Merc 240D  24.4    4  146.7   62  3.69  3.190  20.00   1   0   \n",
       "8              Merc 230  22.8    4  140.8   95  3.92  3.150  22.90   1   0   \n",
       "9              Merc 280  19.2    6  167.6  123  3.92  3.440  18.30   1   0   \n",
       "10            Merc 280C  17.8    6  167.6  123  3.92  3.440  18.90   1   0   \n",
       "11           Merc 450SE  16.4    8  275.8  180  3.07  4.070  17.40   0   0   \n",
       "12           Merc 450SL  17.3    8  275.8  180  3.07  3.730  17.60   0   0   \n",
       "13          Merc 450SLC  15.2    8  275.8  180  3.07  3.780  18.00   0   0   \n",
       "14   Cadillac Fleetwood  10.4    8  472.0  205  2.93  5.250  17.98   0   0   \n",
       "15  Lincoln Continental  10.4    8  460.0  215  3.00  5.424  17.82   0   0   \n",
       "16    Chrysler Imperial  14.7    8  440.0  230  3.23  5.345  17.42   0   0   \n",
       "17             Fiat 128  32.4    4   78.7   66  4.08  2.200  19.47   1   1   \n",
       "18          Honda Civic  30.4    4   75.7   52  4.93  1.615  18.52   1   1   \n",
       "19       Toyota Corolla  33.9    4   71.1   65  4.22  1.835  19.90   1   1   \n",
       "20        Toyota Corona  21.5    4  120.1   97  3.70  2.465  20.01   1   0   \n",
       "21     Dodge Challenger  15.5    8  318.0  150  2.76  3.520  16.87   0   0   \n",
       "22          AMC Javelin  15.2    8  304.0  150  3.15  3.435  17.30   0   0   \n",
       "23           Camaro Z28  13.3    8  350.0  245  3.73  3.840  15.41   0   0   \n",
       "24     Pontiac Firebird  19.2    8  400.0  175  3.08  3.845  17.05   0   0   \n",
       "25            Fiat X1-9  27.3    4   79.0   66  4.08  1.935  18.90   1   1   \n",
       "26        Porsche 914-2  26.0    4  120.3   91  4.43  2.140  16.70   0   1   \n",
       "27         Lotus Europa  30.4    4   95.1  113  3.77  1.513  16.90   1   1   \n",
       "28       Ford Pantera L  15.8    8  351.0  264  4.22  3.170  14.50   0   1   \n",
       "29         Ferrari Dino  19.7    6  145.0  175  3.62  2.770  15.50   0   1   \n",
       "30        Maserati Bora  15.0    8  301.0  335  3.54  3.570  14.60   0   1   \n",
       "31           Volvo 142E  21.4    4  121.0  109  4.11  2.780  18.60   1   1   \n",
       "\n",
       "    gear  carb  \n",
       "0      4     4  \n",
       "1      4     4  \n",
       "2      4     1  \n",
       "3      3     1  \n",
       "4      3     2  \n",
       "5      3     1  \n",
       "6      3     4  \n",
       "7      4     2  \n",
       "8      4     2  \n",
       "9      4     4  \n",
       "10     4     4  \n",
       "11     3     3  \n",
       "12     3     3  \n",
       "13     3     3  \n",
       "14     3     4  \n",
       "15     3     4  \n",
       "16     3     4  \n",
       "17     4     1  \n",
       "18     4     2  \n",
       "19     4     1  \n",
       "20     3     1  \n",
       "21     3     2  \n",
       "22     3     2  \n",
       "23     3     4  \n",
       "24     3     2  \n",
       "25     4     1  \n",
       "26     5     2  \n",
       "27     5     2  \n",
       "28     5     4  \n",
       "29     5     6  \n",
       "30     5     8  \n",
       "31     4     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define URL where dataset is located\n",
    "data = pd.read_csv(\"mtcars.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7504ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77.55789711787898"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For a full model\n",
    "#define response variable\n",
    "Y_full = data['mpg']\n",
    "\n",
    "#define predictor variables\n",
    "X_full = data[['disp', 'carb', 'hp', 'cyl']]\n",
    "\n",
    "#add constant to predictor variables\n",
    "X_full = sm.add_constant(X_full)\n",
    "\n",
    "#fit regression model\n",
    "full_model = sm.OLS(Y_full, X_full).fit()\n",
    "\n",
    "#calculate log-likelihood of model\n",
    "full_ll = full_model.llf\n",
    "full_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda99bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78.60301334355185"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For a nested model\n",
    "#define response variable\n",
    "Y_nested = data['mpg']\n",
    "\n",
    "#define predictor variables\n",
    "X_nested = data[['disp', 'carb']]\n",
    "\n",
    "#add constant to predictor variables\n",
    "X_nested = sm.add_constant(X_nested)\n",
    "\n",
    "#fit regression model\n",
    "reduced_model = sm.OLS(Y_nested, X_nested).fit()\n",
    "\n",
    "#calculate log-likelihood of model\n",
    "reduced_ll = reduced_model.llf\n",
    "reduced_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5077e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood-ratio test statistic is 2.0902324513457415\n",
      "p-value is 0.35165094613502257\n"
     ]
    }
   ],
   "source": [
    "#calculate likelihood ratio Chi-Squared test statistic\n",
    "LR_statistic = -2*(reduced_ll-full_ll)\n",
    "\n",
    "print(\"likelihood-ratio test statistic is\", LR_statistic)\n",
    "\n",
    "#calculate p-value of test statistic using 2 degrees of freedom\n",
    "p_val = scipy.stats.chi2.sf(LR_statistic, 2)\n",
    "\n",
    "print(\"p-value is\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874330eb",
   "metadata": {},
   "source": [
    "Because the calculated p-value = 0.35165094613502257 $\\geq$ significance level $\\alpha$ = 0.05, we do not reject the null hypothesis $H_0$.\n",
    "\n",
    "Therefore, we can use nested regression model to substitute the full regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b68f61",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c89d94",
   "metadata": {},
   "source": [
    "### References for Wald Test Part:\n",
    "- https://en.wikipedia.org/wiki/Likelihood-ratio_test\n",
    "- https://www.probabilitycourse.com/chapter8/8_4_5_likelihood_ratio_tests.php\n",
    "- http://people.missouristate.edu/songfengzheng/Teaching/MTH541/Lecture%20notes/LRT.pdf\n",
    "- https://www.statology.org/likelihood-ratio-test-in-python/\n",
    "\n",
    "### Bibliographical Notes for Wald Test Part:\n",
    "The Wald Test portion of this lecture is largely based on lecture notes from \"Generalized Linear Models\" by Germán Rodríguez at Princeton, lecture notes from \"MS&E 226\" by Ramesh Johari at Stanford, and Chapter 14.1 of the book \"Biostatistics\" by Ronald N. Forthofer, Eun Sul Lee and Mike Hernandez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91937c34",
   "metadata": {},
   "source": [
    "### References for Likelihood-ratio Test Part:\n",
    "- https://web-s-ebscohost-com.ezproxy.library.wisc.edu/ehost/ebookviewer/ebook/bmxlYmtfXzE4NTc0OF9fQU41?sid=9645d4ef-3afc-42db-8ee2-fa5a7476607b@redis&vid=0&format=EB&lpid=lp_387&rid=0\n",
    "- https://data.princeton.edu/wws509/notes/c2s3\n",
    "- https://www.statisticshowto.com/wald-test/\n",
    "- https://web.stanford.edu/~rjohari/teaching/notes/226_lecture15_inference.pdf\n",
    "\n",
    "### Bibliographical Notes for Likelihood-ratio Test Part:\n",
    "The likelihood-ratio test part is largely based on \"Likelihood-ratio test\" from wikipedia, Chapter 8.4.5 in \"Introduction to Probability, Statistics, and Random Processes\" by Hossein Pishro-Nik, lecture notes from \"Math 541: Statistical Theory II\" by Songfeng Zheng, and \"How to Perform a Likelihood Ratio Test in Python\" by Zach, as a final final project for COMP SCI 639."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a48bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
